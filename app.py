import streamlit as st
import requests
import replicate
from pydub import AudioSegment
import os
from pydub.utils import which

# ffmpeg ì„¤ì¹˜ í›„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ ë†”ì„œ ì•„ë˜ì™€ ê°™ì€ ëª…ì‹œì  ê²½ë¡œ í‘œê¸° ë¶ˆí•„ìš”
# AudioSegment.converter = "C:\\ffmpeg\\ffmpeg-7.1.1-essentials_build\\bin\\ffmpeg.exe"
# AudioSegment.ffprobe   = "C:\\ffmpeg\\ffmpeg-7.1.1-essentials_build\\bin\\ffprobe.exe"
# AudioSegment.converter = which("ffmpeg")
# AudioSegment.ffprobe   = which("ffprobe")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "music_versions" not in st.session_state:
    # ê° ìŒì•… ë²„ì „ì˜ ì •ë³´ (ë²„ì „ëª…, LLM ìƒì„± í”„ë¡¬í”„íŠ¸, ì˜¤ë””ì˜¤ URL, ê¸°ë°˜ í…ìŠ¤íŠ¸/êµ¬ì ˆ)ë¥¼ ì €ì¥
    st.session_state.music_versions = []

if "current_book_description" not in st.session_state:
    st.session_state.current_book_description = "" # ì´ˆê¸° ì±… ì„¤ëª… ì €ì¥ìš©
if "last_llm_generated_prompt" not in st.session_state:
    st.session_state.last_llm_generated_prompt = "" # LLMì´ ê°€ì¥ ìµœê·¼ì— ìƒì„±í•œ ìŒì•… í”„ë¡¬í”„íŠ¸

# --- API í˜¸ì¶œ í•¨ìˆ˜ë“¤ ---
def get_book_description_from_api(book_title, book_author):
    """Google Books APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì±… ì„¤ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    query = f"{book_title}+inauthor:{book_author}"
    try:
        response = requests.get(f"https://www.googleapis.com/books/v1/volumes?q={query}")
        response.raise_for_status()
        items = response.json().get("items")
        if not items:
            return None, "ì±… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œëª©ê³¼ ì €ìëª…ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
        description = items[0]["volumeInfo"].get("description", "ì´ ì±…ì— ëŒ€í•œ ì„¤ëª…ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return description, None
    except requests.exceptions.RequestException as e:
        return None, f"Google Books API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    except Exception as e:
        return None, f"ì±… ì„¤ëª… ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}"
    
def generate_music_prompt_with_llm(input_text_for_llm, existing_prompt_from_llm=None):
    """
    Replicate LLM (GPT-4o-mini)ì„ ì‚¬ìš©í•˜ì—¬ ìŒì•… ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    LLMì´ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì™€ ìƒˆë¡œìš´ êµ¬ì ˆì„ 'ì´í•´'í•˜ê³  'ìƒˆë¡œìš´' í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
    input_text_for_llm: ì±… ì„¤ëª… (ì´ˆê¸°) ë˜ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¸ìƒ ê¹Šì€ êµ¬ì ˆ (ì—…ë°ì´íŠ¸ ì‹œ)
    existing_prompt_from_llm: ì—…ë°ì´íŠ¸ì˜ ê¸°ë°˜ì´ ë , ì´ì „ì— LLMì´ ìƒì„±í–ˆë˜ ìŒì•… í”„ë¡¬í”„íŠ¸
    """
    prompt_guidance = ""
    if existing_prompt_from_llm:
        # í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ LLMì—ê²Œ ì „ë‹¬í•  ì§€ì‹œë¬¸
        prompt_guidance = (
            f"You are an expert music prompt engineer. Your task is to creatively update an existing music prompt "
            f"This is a continuation of the previous section. Do NOT change the core instrumentation or tempo. Maintain the same key and emotional tone."
            f"based on new input. \n\n"
            f"The PREVIOUS music prompt (created by an AI) was: '{existing_prompt_from_llm}'\n\n"
            f"The NEW user-provided inspiring passage/idea to incorporate is: '{input_text_for_llm}'\n\n"
            f"Note: The new input is a specific passage from the same book that the user found emotionally impactful while reading.\n\n"
            f"INSTRUCTIONS: Analyze both the previous prompt and the new passage. "
            f"Generate a new and coherent music prompt that smoothly continues from the previous one, while thoughtfully integrating the emotional and thematic essence of the new passage. "
            f"The new prompt should seamlessly continue from the previous music, maintaining musical consistency in tone, mood, and instrumentation. "
            f"Do not restart or reset the compositionâ€”think of this as a musical continuation or next chapter. "
            f"DO NOT simply append the new passage to the old prompt. Instead, RE-IMAGINE and RE-WRITE a fresh prompt. "
            f"The music should remain instrumental, suitable for background listening while reading, typically relaxing, and strictly without vocals or lyrics. "
            f"Focus on translating the combined mood and ideas into actionable musical directions for an AI music generator. "
            f"Output ONLY the new, complete music prompt. No conversational phrases, acknowledgements, or any text other than the music prompt itself."
            f"End the piece with a gentle fade-out that feels natural and seamlessly leaves room for silence or the next musical section."
            f"The music should last exactly 60 seconds. End the piece with a gentle fade-out during the last 5â€“10 seconds, gradually reducing the volume and thinning out the instrumentation. This will help the track flow smoothly into the next piece without abrupt transitions."
        )

    else:
        # ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œ LLMì—ê²Œ ì „ë‹¬í•  ì§€ì‹œë¬¸
        prompt_guidance = (
            f"The following is a book description: '{input_text_for_llm}'. "
            f"Based solely on this description, create a concise and emotionally resonant prompt for generating instrumental background music. "
            f"The music should be suitable for focused reading, containing a gentle melody and smooth flow. "
            f"Begin with a soft fade-in. Include a simple melodic motif that captures the mood and theme expressed in the book description. "
            f"Use ambient textures only as a subtle background. Choose no more than 2â€“3 instruments from: soft piano, acoustic guitar, light strings (cello or viola), ambient synth, and subtle nature sounds (optional). "
            f"Avoid speculative interpretations beyond the description. Do not conclude the pieceâ€”leave it open-ended for future continuation. "
            f"Output only the final music prompt, with no extra explanations or conversational phrases."
            f"End the piece with a gentle fade-out that feels natural and seamlessly leaves room for silence or the next musical section."
            f"The music should last exactly 60 seconds. End the piece with a gentle fade-out during the last 5â€“10 seconds, gradually reducing the volume and thinning out the instrumentation. This will help the track flow smoothly into the next piece without abrupt transitions."
        )

    try:
        output = replicate.run(
            "openai/gpt-4o-mini",
            input={
                "prompt": prompt_guidance,
                "temperature": 0.75, # ì•½ê°„ì˜ ì°½ì˜ì„±ì„ ë” ë¶€ì—¬
                "max_completion_tokens": 350 # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ë¥¼ ì¡°ê¸ˆ ë” ì—¬ìœ ìˆê²Œ
            }
        )
        llm_generated_music_prompt = "".join(output) if isinstance(output, list) else str(output)
        return llm_generated_music_prompt.strip(), None
    except replicate.exceptions.ReplicateError as e:
        return None, f"Replicate LLM API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return None, f"ìŒì•… í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}"
    

def generate_music_with_musicgen_api(prompt_for_musicgen, duration=60):
    """Replicate MusicGenì„ ì‚¬ìš©í•˜ì—¬ ìŒì•…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        output = replicate.run(
            "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb",
            input={
                "prompt": prompt_for_musicgen,
                "model_version": "stereo-large",
                "output_format": "mp3",
                "duration": duration,
                "normalization_strategy": "peak"
            }
        )
        audio_url_generated = str(output)
        return audio_url_generated, None
    except replicate.exceptions.ReplicateError as e:
        return None, f"Replicate MusicGen API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return None, f"ìŒì•… ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}"
    
def download_and_fade_audio(audio_url, index, fade_out_ms=5000):
    os.makedirs("outputs", exist_ok=True)
    path = os.path.abspath(os.path.join("outputs", f"v{index}.mp3"))
    try:
        response = requests.get(audio_url)
        response.raise_for_status()
        with open(path, "wb") as f:
            f.write(response.content)
        print(f"[DEBUG] íŒŒì¼ ì €ì¥ ì™„ë£Œ: {path}")
    except Exception as e:
        print(f"[ERROR] íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise
    try:
        sound = AudioSegment.from_file(path, format="mp3")
        return sound.fade_out(fade_out_ms)
    except Exception as e:
        print(f"[ERROR] ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def combine_tracks_with_crossfade(audio_segments, crossfade_ms=3000):
    combined = audio_segments[0]
    for seg in audio_segments[1:]:
        combined = combined.append(seg, crossfade=crossfade_ms)
    return combined

def export_combined_to_local(combined_audio, filename="combined_output.mp3"):
    os.makedirs("outputs", exist_ok=True)
    path = os.path.join("outputs", filename)
    combined_audio.export(path, format="mp3")
    return path

# âœ… ìƒˆë¡œ ì¶”ê°€: ìƒì„± ì§í›„ ê° ë²„ì „ mp3 ì €ì¥
if "music_versions" in st.session_state:
    for idx, version in enumerate(st.session_state.music_versions):
        audio_url = version.get("audio_url")
        if audio_url:
            path = os.path.join("outputs", f"v{idx}.mp3")
            if not os.path.exists(path):
                try:
                    _ = download_and_fade_audio(audio_url, index=idx)
                except Exception as e:
                    st.error(f"v{idx} mp3 ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                    st.stop()  

# --- Streamlit UI ---
st.set_page_config(layout="wide")
st.title("ë„ì„œ ê¸°ë°˜ ìŒì•… ìƒì„±ê¸°")
# --- 1ë‹¨ê³„: ì±… ì •ë³´ ì…ë ¥ ë° ì´ˆê¸° ìŒì•… ìƒì„± (v0) ---
# v0ëŠ” ì•„ì§ ìƒì„±ëœ ìŒì•…ì´ ì—†ì„ ë•Œë§Œ ì…ë ¥ í¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
if not st.session_state.music_versions:
    st.header("Step 1: ì±… ì •ë³´ë¡œ ì²« ë²ˆì§¸ ìŒì•…(v0) ë§Œë“¤ê¸°")
    with st.form("v0_music_form"):
        book_title_v0 = st.text_input("ì±… ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", key="book_title_v0")
        book_author_v0 = st.text_input("ì €ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", key="book_author_v0")
        submitted_v0 = st.form_submit_button("v0 ìŒì•… ìƒì„±í•˜ê¸°")
    if submitted_v0 and book_title_v0 and book_author_v0:
        with st.spinner("ì±… ì„¤ëª… ê²€ìƒ‰ ì¤‘..."):
            description, error = get_book_description_from_api(book_title_v0, book_author_v0)
            if error:
                st.error(error)
                st.stop()
            st.session_state.current_book_description = description
            st.success("ì±… ì„¤ëª…ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
            st.markdown(f"*ê¸°ë°˜ ì±… ì„¤ëª… (ìš”ì•½):* {description[:300]}...")
        with st.spinner("v0 ìŒì•… í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ (GPT-4o-mini)..."):
            # ì´ˆê¸° í”„ë¡¬í”„íŠ¸ëŠ” ì±… ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„± (existing_prompt_from_llm=None)
            llm_prompt_v0, error = generate_music_prompt_with_llm(description)
            if error:
                st.error(error)
                st.stop()
            st.session_state.last_llm_generated_prompt = llm_prompt_v0 # ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì €ì¥
            st.success("v0 ìŒì•… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
        with st.spinner("v0 ìŒì•… ìƒì„± ì¤‘ (MusicGen)... ì•½ 1~2ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
            audio_url_v0, error = generate_music_with_musicgen_api(llm_prompt_v0)
            if error:
                st.error(error)
                st.stop()
            # ìƒì„±ëœ v0 ìŒì•… ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            st.session_state.music_versions.append({
                "version_name": f"v{len(st.session_state.music_versions)} (ì´ˆê¸° - ì±… ì„¤ëª… ê¸°ë°˜)",
                "llm_prompt": llm_prompt_v0,
                "audio_url": audio_url_v0,
                "based_on_text": f"ì±… ì„¤ëª…: {description[:100]}..."
            })
            st.session_state["audio_url_v0"] = audio_url_v0
            try:
                _ = download_and_fade_audio(audio_url_v0, index=0)
            except Exception as e:
                st.error(f"v0 mp3 ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            st.success("v0 ìŒì•…ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.balloons()
            st.experimental_rerun()

 # UIë¥¼ ë‹¤ì‹œ ê·¸ë ¤ì„œ ìŒì•… ëª©ë¡ê³¼ ë‹¤ìŒ ë‹¨ê³„ UIê°€ ë³´ì´ë„ë¡ í•¨
# --- ìƒì„±ëœ ìŒì•… ëª©ë¡ í‘œì‹œ ---
if st.session_state.music_versions:
    st.write("---")
    st.header("ìƒì„±ëœ ìŒì•… íˆìŠ¤í† ë¦¬")
    # ì˜¤ë˜ëœ ë²„ì „ë¶€í„° ìˆœì„œëŒ€ë¡œ í‘œì‹œ
    for i, music_info in enumerate(st.session_state.music_versions):
        with st.expander(f"*{music_info['version_name']}* - '{music_info['llm_prompt'][:40]}...' í”„ë¡¬í”„íŠ¸ ê¸°ë°˜", expanded=(i == len(st.session_state.music_versions) - 1)): # ìµœì‹  ìŒì•…ë§Œ í¼ì³ë³´ê¸°
            st.caption(f"ìƒì„± ê¸°ë°˜: {music_info['based_on_text']}")
            st.info(f"LLM ìƒì„± ìŒì•… í”„ë¡¬í”„íŠ¸:*\n{music_info['llm_prompt']}")
            st.audio(music_info["audio_url"], format="audio/mp3")
            st.write("---")
# --- 2ë‹¨ê³„: ì¸ìƒ ê¹Šì€ êµ¬ì ˆë¡œ ë‹¤ìŒ ë²„ì „ ìŒì•… ìƒì„± (v0 ìŒì•… ìƒì„± í›„ í™œì„±í™”) ---
if st.session_state.music_versions: # ìƒì„±ëœ ìŒì•…ì´ í•˜ë‚˜ë¼ë„ ìˆì„ ê²½ìš° ë‹¤ìŒ ë²„ì „ ìƒì„± UI í‘œì‹œ
    st.write("---")
    next_version_num = len(st.session_state.music_versions)
    st.header(f"Step 2: ì¸ìƒ ê¹Šì€ êµ¬ì ˆë¡œ ë‹¤ìŒ ìŒì•…(v{next_version_num}) ë§Œë“¤ê¸°")
    with st.form(f"v_next_music_form"):
        new_passage_input = st.text_area(
            "ìŒì•…ì— ìƒˆë¡­ê²Œ ë°˜ì˜í•˜ê³  ì‹¶ì€ ì¸ìƒ ê¹Šì€ êµ¬ì ˆì´ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            height=150,
            key=f"passage_input_v{next_version_num}",
            placeholder="ì˜ˆ: 'ê³ ìš”í•œ ë°¤, ë³„ë¹› ì•„ë˜ í™€ë¡œ ê±·ëŠ” ì£¼ì¸ê³µì˜ ì™¸ë¡­ì§€ë§Œ í‰í™”ë¡œìš´ ê°ì •'"
        )
        duration_next_music = 60 # ìƒì„±í•  ìŒì•… ê¸¸ì´
        submitted_next_music = st.form_submit_button(f"v{next_version_num} ìŒì•… ìƒì„±í•˜ê¸°")
    if submitted_next_music and new_passage_input:
        if not st.session_state.last_llm_generated_prompt:
            st.error("ì˜¤ë¥˜: ì—…ë°ì´íŠ¸ì˜ ê¸°ë°˜ì´ ë  ì´ì „ AI ìƒì„± ìŒì•… í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € v0 ìŒì•…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            st.stop()
        with st.spinner(f":ë†’ì€ìŒìë¦¬í‘œ: v{next_version_num} ìŒì•… í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ (GPT-4o-mini)..."):
            # ì—…ë°ì´íŠ¸ ì‹œì—ëŠ” 'ì‚¬ìš©ì ì…ë ¥ êµ¬ì ˆ'ê³¼ 'ì´ì „ì— LLMì´ ìƒì„±í•œ ìŒì•… í”„ë¡¬í”„íŠ¸'ë¥¼ í•¨ê»˜ ì‚¬ìš©
            updated_llm_prompt, error = generate_music_prompt_with_llm(
                new_passage_input,
                existing_prompt_from_llm=st.session_state.last_llm_generated_prompt # ì´ì „ LLM ìƒì„± í”„ë¡¬í”„íŠ¸ ì „ë‹¬
            )
            if error:
                st.error(error)
                st.stop()
            st.session_state.last_llm_generated_prompt = updated_llm_prompt # ìµœì‹  LLM ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ì—…ë°ì´íŠ¸
            st.success(f"v{next_version_num} ìŒì•… í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
        with st.spinner(f":ìŒí‘œ: v{next_version_num} ìŒì•… ìƒì„± ì¤‘ (MusicGen)... ì•½ {duration_next_music // 60 + 1}ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
            new_audio_url, error = generate_music_with_musicgen_api(updated_llm_prompt, duration_next_music)
            if error:
                st.error(error)
                st.stop()
            # ìƒì„±ëœ ë‹¤ìŒ ë²„ì „ ìŒì•… ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            st.session_state.music_versions.append({
                "version_name": f"v{next_version_num} (êµ¬ì ˆ ì¶”ê°€)",
                "llm_prompt": updated_llm_prompt,
                "audio_url": new_audio_url,
                "based_on_text": f"ì¶”ê°€ëœ êµ¬ì ˆ: {new_passage_input[:100]}... (ì´ì „ í”„ë¡¬í”„íŠ¸: '{st.session_state.music_versions[-2]['llm_prompt'][:30]}...' ê¸°ë°˜)" if len(st.session_state.music_versions) > 1 else f"ì¶”ê°€ëœ êµ¬ì ˆ: {new_passage_input[:100]}..."
            })
            st.session_state["new_audio_url"] = new_audio_url
            try:
                _ = download_and_fade_audio(new_audio_url, index=next_version_num)
            except Exception as e:
                st.error(f"v{next_version_num} mp3 ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            st.success(f":ì§ : v{next_version_num} ìŒì•…ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.balloons()
            st.experimental_rerun() # UIë¥¼ ë‹¤ì‹œ ê·¸ë ¤ì„œ ìŒì•… ëª©ë¡ ì—…ë°ì´íŠ¸ ë° ë‹¤ìŒ ì…ë ¥ í¼ ì¤€ë¹„
    elif submitted_next_music and not new_passage_input:
        st.warning("ìŒì•…ì— ë°˜ì˜í•  ì¸ìƒ ê¹Šì€ êµ¬ì ˆì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
# --- ì‚¬ì´ë“œë°” ì •ë³´ ---
st.sidebar.header("ì‚¬ìš© ë°©ë²•")
st.sidebar.markdown("""
1.  *Step 1 (ì´ˆê¸° ìŒì•… ìƒì„± - v0):*
    *   ì±… ì œëª©ê³¼ ì €ì ì´ë¦„ì„ ì…ë ¥í•˜ê³  'v0 ìŒì•… ìƒì„±í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.
    *   ì±… ì„¤ëª… ê¸°ë°˜ì˜ ì²« ë²ˆì§¸ ìŒì•…(v0)ê³¼ í•´ë‹¹ ìŒì•… ìƒì„±ì— ì‚¬ìš©ëœ AI í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì–´ í‘œì‹œë©ë‹ˆë‹¤.
2.  *Step 2 (ë‹¤ìŒ ë²„ì „ ìŒì•… ìƒì„± - v1, v2...):*
    *   v0 ìŒì•…ì´ ìƒì„±ëœ í›„, 'Step 2' ì„¹ì…˜ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
    *   ìŒì•…ì— ìƒˆë¡­ê²Œ ë°˜ì˜í•˜ê³  ì‹¶ì€ ì¸ìƒ ê¹Šì€ êµ¬ì ˆì´ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
    *   'vN ìŒì•… ìƒì„±í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, *ì´ì „ì— AIê°€ ë§Œë“¤ì—ˆë˜ ìŒì•… í”„ë¡¬í”„íŠ¸*ì™€ *ìƒˆë¡œìš´ êµ¬ì ˆ*ì„ AIê°€ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ *ì°½ì˜ì ìœ¼ë¡œ ì¬êµ¬ì„±í•œ ìƒˆ í”„ë¡¬í”„íŠ¸*ë¡œ ë‹¤ìŒ ë²„ì „ì˜ ìŒì•…ì´ ìƒì„±ë©ë‹ˆë‹¤.
    *   ìƒì„±ëœ ëª¨ë“  ë²„ì „ì˜ ìŒì•…ê³¼ í”„ë¡¬í”„íŠ¸ëŠ” íˆìŠ¤í† ë¦¬ ëª©ë¡ì— ëˆ„ì ë˜ì–´ í‘œì‹œë©ë‹ˆë‹¤.
""")
st.sidebar.markdown("---")
st.sidebar.caption("Powered by Replicate (GPT-4o-mini, MusicGen) & Google Books API")

# --- ì—°ì† íŠ¸ë™ ë§Œë“¤ê¸° ê¸°ëŠ¥ ì¶”ê°€ ---
if st.button("ëª¨ë“  ìŒì•… ì´ì–´ë¶™ì´ê¸° (crossfade ì ìš©)"):
    try:
        audio_segments = []

        for i, version in enumerate(st.session_state.music_versions):
            path = os.path.abspath(os.path.join("outputs", f"v{i}.mp3"))
            if not os.path.exists(path):
                st.warning(f"[SKIP] íŒŒì¼ ëˆ„ë½: outputs/v{i}.mp3")
                continue
            try:
                seg = AudioSegment.from_file(path, format="mp3") # ë‚´ë¶€ì ìœ¼ë¡œ ffmpeg ì‹¤í–‰
                audio_segments.append(seg.fade_out(5000))
            except Exception as e:
                st.warning(f"[SKIP] íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: outputs/v{i}.mp3: {e}")
                continue

        if len(audio_segments) < 2:
            st.error("âš ï¸ ì´ì–´ë¶™ì¼ ìˆ˜ ìˆëŠ” mp3ê°€ 2ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            combined = combine_tracks_with_crossfade(audio_segments)
            final_path = export_combined_to_local(combined, filename="combined_output.mp3")
            st.success("âœ… ì—°ì† íŠ¸ë™ ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ ì¬ìƒí•´ë³´ì„¸ìš” ğŸµ")
            st.audio(final_path, format="audio/mp3")

    except Exception as e:
        st.error(f"íŠ¸ë™ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")